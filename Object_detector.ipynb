{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YOLOv5 Tutorial",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cef5e9351ca743bcba5febac0b096a30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ec326c52378f4410920c328f221e0514",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_83000c64a11c4ae8abd6f0ef2f108cef",
              "IPY_MODEL_0f7899eb719f4a9c9852426551f97be9"
            ]
          }
        },
        "ec326c52378f4410920c328f221e0514": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "83000c64a11c4ae8abd6f0ef2f108cef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_886ac5b18b3c4c82bf15ad5055f1e17e",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 819257867,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 819257867,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4e67b3c3a49849c7a7ba28b7eec96e7a"
          }
        },
        "0f7899eb719f4a9c9852426551f97be9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_62c3682ff1804571a483d46664533969",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 781M/781M [00:12&lt;00:00, 67.1MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_599dda3b608b432393760b2ca4ae7c7d"
          }
        },
        "886ac5b18b3c4c82bf15ad5055f1e17e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4e67b3c3a49849c7a7ba28b7eec96e7a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "62c3682ff1804571a483d46664533969": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "599dda3b608b432393760b2ca4ae7c7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "217ca488c82a4b7a80318b70887a556e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4e63af16f1084ca98a6fa5a282f2a81e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_49f4b3c7f6ff42b4b9132a8550e12186",
              "IPY_MODEL_8ec9e1a4883245daaf029458ee09721f"
            ]
          }
        },
        "4e63af16f1084ca98a6fa5a282f2a81e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "49f4b3c7f6ff42b4b9132a8550e12186": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9d3e775ee11e4cf4b587b64fbc3cc6f7",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 22091032,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 22091032,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_70f68a9a51ac46e6ab7e51fb4fc6bda3"
          }
        },
        "8ec9e1a4883245daaf029458ee09721f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_fdb8ab377c114bc3b862ba76eb93cef7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 21.1M/21.1M [00:36&lt;00:00, 605kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cd267c153c244621a1f50706d2ddc897"
          }
        },
        "9d3e775ee11e4cf4b587b64fbc3cc6f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "70f68a9a51ac46e6ab7e51fb4fc6bda3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fdb8ab377c114bc3b862ba76eb93cef7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cd267c153c244621a1f50706d2ddc897": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chanakya26/Opencv-projects/blob/main/Object_detector.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6MPjfT5NrKQ"
      },
      "source": [
        "<a align=\"left\" href=\"https://ultralytics.com/yolov5\" target=\"_blank\">\n",
        "<img src=\"https://github.com/ultralytics/yolov5/releases/download/v1.0/splash_horizontal.png\"></a>\n",
        "\n",
        "This is the **official YOLOv5 ðŸš€ notebook** authored by **Ultralytics**, and is freely available for redistribution under the [GPL-3.0 license](https://choosealicense.com/licenses/gpl-3.0/). \n",
        "For more information please visit https://github.com/ultralytics/yolov5 and https://ultralytics.com. Thank you!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mGmQbAO5pQb"
      },
      "source": [
        "# Setup\n",
        "\n",
        "Clone repo, install dependencies and check PyTorch and GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbvMlHd_QwMG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4af96237-a853-4395-8151-7c189633efb4"
      },
      "source": [
        "!git clone https://github.com/ultralytics/yolov5  # clone repo\n",
        "%cd yolov5\n",
        "%pip install -qr requirements.txt  # install dependencies\n",
        "\n",
        "import torch\n",
        "from IPython.display import Image, clear_output  # to display images\n",
        "\n",
        "clear_output()\n",
        "print(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Setup complete. Using torch 1.9.0+cu102 (Tesla T4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JnkELT0cIJg"
      },
      "source": [
        "# 1. Inference\n",
        "\n",
        "`detect.py` runs YOLOv5 inference on a variety of sources, downloading models automatically from the [latest YOLOv5 release](https://github.com/ultralytics/yolov5/releases), and saving results to `runs/detect`. Example inference sources are:\n",
        "\n",
        "<img src=\"https://user-images.githubusercontent.com/26833433/114307955-5c7e4e80-9ae2-11eb-9f50-a90e39bee53f.png\" width=\"900\"> "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGGvjSkjaANh",
        "outputId": "42fa748b-9a03-445f-e8bf-f4a2de81da3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!unzip -q ../train_data.zip -d ../"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "replace ../train_data/images/train/1.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zR9ZbuQCH7FX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1efb01a-fe47-4f68-c73a-c7184dd0ed3e"
      },
      "source": [
        "!python detect.py --weights runs/train/exp4/weights/last.pt --img 640 --conf 0.25 --source ../mark2.jpg\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['runs/train/exp4/weights/last.pt'], source=../mark2.jpg, imgsz=640, conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False\n",
            "YOLOv5 ðŸš€ v5.0-250-g02719dd torch 1.9.0+cu102 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Fusing layers... \n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
            "Model Summary: 224 layers, 7053910 parameters, 0 gradients, 16.3 GFLOPs\n",
            "image 1/1 /content/yolov5/../mark2.jpg: 512x640 1 dustbin, Done. (0.014s)\n",
            "Results saved to runs/detect/exp2\n",
            "Done. (0.021s)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eq1SMWl6Sfn"
      },
      "source": [
        "# 2. Test\n",
        "Test a model's accuracy on [COCO](https://cocodataset.org/#home) val or test-dev datasets. Models are downloaded automatically from the [latest YOLOv5 release](https://github.com/ultralytics/yolov5/releases). To show results by class use the `--verbose` flag. Note that `pycocotools` metrics may be ~1% better than the equivalent repo metrics, as is visible below, due to slight differences in mAP computation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eyTZYGgRjnMc"
      },
      "source": [
        "## COCO val2017\n",
        "Download [COCO val 2017](https://github.com/ultralytics/yolov5/blob/74b34872fdf41941cddcf243951cdb090fbac17b/data/coco.yaml#L14) dataset (1GB - 5000 images), and test model accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQPtK1QYVaD_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "cef5e9351ca743bcba5febac0b096a30",
            "ec326c52378f4410920c328f221e0514",
            "83000c64a11c4ae8abd6f0ef2f108cef",
            "0f7899eb719f4a9c9852426551f97be9",
            "886ac5b18b3c4c82bf15ad5055f1e17e",
            "4e67b3c3a49849c7a7ba28b7eec96e7a",
            "62c3682ff1804571a483d46664533969",
            "599dda3b608b432393760b2ca4ae7c7d"
          ]
        },
        "outputId": "56b6402a-81d5-41d0-a3c8-8889db1fca6c"
      },
      "source": [
        "# Download COCO val2017\n",
        "torch.hub.download_url_to_file('https://github.com/ultralytics/yolov5/releases/download/v1.0/coco2017val.zip', 'tmp.zip')\n",
        "!unzip -q tmp.zip -d ../ && rm tmp.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cef5e9351ca743bcba5febac0b096a30",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=819257867.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X58w8JLpMnjH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5d41761-f1a0-41fe-d0bb-4cceebd7c4a6"
      },
      "source": [
        "# Run YOLOv5x on COCO val2017\n",
        "!python test.py --weights yolov5x.pt --data coco.yaml --img 640 --iou 0.65 --half"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Namespace(augment=False, batch_size=32, conf_thres=0.001, data='./data/coco.yaml', device='', exist_ok=False, half=True, img_size=640, iou_thres=0.65, name='exp', project='runs/test', save_conf=False, save_hybrid=False, save_json=True, save_txt=False, single_cls=False, task='val', verbose=False, weights=['yolov5x.pt'])\n",
            "YOLOv5 ðŸš€ v5.0-157-gc6b51f4 torch 1.8.1+cu101 CUDA:0 (Tesla V100-SXM2-16GB, 16160.5MB)\n",
            "\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v5.0/yolov5x.pt to yolov5x.pt...\n",
            "100% 168M/168M [00:01<00:00, 156MB/s]\n",
            "\n",
            "Fusing layers... \n",
            "Model Summary: 476 layers, 87730285 parameters, 0 gradients\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '../coco/val2017' images and labels...4952 found, 48 missing, 0 empty, 0 corrupted: 100% 5000/5000 [00:01<00:00, 3008.87it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: ../coco/val2017.cache\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 157/157 [01:17<00:00,  2.02it/s]\n",
            "                 all       5000      36335      0.746      0.626       0.68       0.49\n",
            "Speed: 5.3/1.5/6.8 ms inference/NMS/total per 640x640 image at batch-size 32\n",
            "\n",
            "Evaluating pycocotools mAP... saving runs/test/exp/yolov5x_predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.44s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=4.88s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=83.47s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=12.96s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.504\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.688\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.546\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.351\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.551\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.644\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.382\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.629\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.681\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.524\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.735\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.827\n",
            "Results saved to runs/test/exp\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rc_KbFk0juX2"
      },
      "source": [
        "## COCO test-dev2017\n",
        "Download [COCO test2017](https://github.com/ultralytics/yolov5/blob/74b34872fdf41941cddcf243951cdb090fbac17b/data/coco.yaml#L15) dataset (7GB - 40,000 images), to test model accuracy on test-dev set (**20,000 images, no labels**). Results are saved to a `*.json` file which should be **zipped** and submitted to the evaluation server at https://competitions.codalab.org/competitions/20794."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0AJnSeCIHyJ"
      },
      "source": [
        "# Download COCO test-dev2017\n",
        "torch.hub.download_url_to_file('https://github.com/ultralytics/yolov5/releases/download/v1.0/coco2017labels.zip', 'tmp.zip')\n",
        "!unzip -q tmp.zip -d ../ && rm tmp.zip # unzip labels\n",
        "!f=\"test2017.zip\" && curl http://images.cocodataset.org/zips/$f -o $f && unzip -q $f && rm $f  # 7GB,  41k images\n",
        "%mv ./test2017 ../coco/images  # move to /coco"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29GJXAP_lPrt"
      },
      "source": [
        "# Run YOLOv5s on COCO test-dev2017 using --task test\n",
        "!python test.py --weights yolov5s.pt --data coco.yaml --task test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUOiNLtMP5aG"
      },
      "source": [
        "# 3. Train\n",
        "\n",
        "Download [COCO128](https://www.kaggle.com/ultralytics/coco128), a small 128-image tutorial dataset, start tensorboard and train YOLOv5s from a pretrained checkpoint for 3 epochs (note actual training is typically much longer, around **300-1000 epochs**, depending on your dataset)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Knxi2ncxWffW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "217ca488c82a4b7a80318b70887a556e",
            "4e63af16f1084ca98a6fa5a282f2a81e",
            "49f4b3c7f6ff42b4b9132a8550e12186",
            "8ec9e1a4883245daaf029458ee09721f",
            "9d3e775ee11e4cf4b587b64fbc3cc6f7",
            "70f68a9a51ac46e6ab7e51fb4fc6bda3",
            "fdb8ab377c114bc3b862ba76eb93cef7",
            "cd267c153c244621a1f50706d2ddc897"
          ]
        },
        "outputId": "9e4788c2-e1d4-4a13-c3d2-984f5df7ffab"
      },
      "source": [
        "# Download COCO128\n",
        "torch.hub.download_url_to_file('https://github.com/ultralytics/yolov5/releases/download/v1.0/coco128.zip', 'tmp.zip')\n",
        "!unzip -q tmp.zip -d ../ && rm tmp.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "217ca488c82a4b7a80318b70887a556e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=22091032.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pOkGLv1dMqh"
      },
      "source": [
        "Train a YOLOv5s model on [COCO128](https://www.kaggle.com/ultralytics/coco128) with `--data coco128.yaml`, starting from pretrained `--weights yolov5s.pt`, or from randomly initialized `--weights '' --cfg yolov5s.yaml`. Models are downloaded automatically from the [latest YOLOv5 release](https://github.com/ultralytics/yolov5/releases), and **COCO, COCO128, and VOC datasets are downloaded automatically** on first use.\n",
        "\n",
        "All training results are saved to `runs/train/` with incrementing run directories, i.e. `runs/train/exp2`, `runs/train/exp3` etc.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOy5KI2ncnWd"
      },
      "source": [
        "# Tensorboard  (optional)\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir runs/train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fLAV42oNb7M"
      },
      "source": [
        "# Weights & Biases  (optional)\n",
        "%pip install -q wandb\n",
        "import wandb\n",
        "wandb.login()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NcFxRcFdJ_O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0c5de84-5510-4e8e-8070-51d1fde30edc"
      },
      "source": [
        "# Train YOLOv5s on COCO128 for 3 epochs\n",
        "!python train.py --img 640 --batch 2 --epochs 60 --data custom_data1.yaml --weights yolov5s.pt --cache"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=custom_data1.yaml, hyp=data/hyps/hyp.scratch.yaml, epochs=60, batch_size=2, img_size=[640], rect=False, resume=False, nosave=False, notest=False, noautoanchor=False, evolve=False, bucket=, cache_images=True, image_weights=False, device=, multi_scale=False, single_cls=False, adam=False, sync_bn=False, workers=8, project=runs/train, entity=None, name=exp, exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, upload_dataset=False, bbox_interval=-1, save_period=-1, artifact_alias=latest, local_rank=-1\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 âœ…\n",
            "YOLOv5 ðŸš€ v5.0-250-g02719dd torch 1.9.0+cu102 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.2, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0\n",
            "\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "2021-06-29 06:30:55.990906: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[34m\u001b[1mwandb: \u001b[0mInstall Weights & Biases for YOLOv5 logging with 'pip install wandb' (recommended)\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  1    156928  models.common.C3                        [128, 128, 3]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  1    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
            "  9                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     16182  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
            "Model Summary: 283 layers, 7063542 parameters, 7063542 gradients, 16.4 GFLOPs\n",
            "\n",
            "Transferred 356/362 items from yolov5s.pt\n",
            "Scaled weight_decay = 0.0005\n",
            "Optimizer groups: 62 .bias, 62 conv.weight, 59 other\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '../train_data/labels/train.cache' images and labels... 18 found, 0 missing, 0 empty, 0 corrupted: 100% 18/18 [00:00<00:00, 145467.19it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.0GB): 100% 18/18 [00:00<00:00, 176.91it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '../train_data/labels/val.cache' images and labels... 11 found, 0 missing, 0 empty, 0 corrupted: 100% 11/11 [00:00<00:00, 66099.35it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.0GB): 100% 11/11 [00:00<00:00, 123.35it/s]\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "Plotting labels... \n",
            "\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 4.04, Best Possible Recall (BPR) = 1.0000\n",
            "Image sizes 640 train, 640 test\n",
            "Using 2 dataloader workers\n",
            "Logging results to runs/train/exp4\n",
            "Starting training for 60 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      0/59    0.512G    0.0921   0.03229         0    0.1244         9       640: 100% 9/9 [00:03<00:00,  2.73it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:00<00:00, 14.84it/s]\n",
            "                 all         11         16     0.0831     0.0625    0.00845    0.00253\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      1/59    0.581G   0.08764   0.03062         0    0.1183         9       640: 100% 9/9 [00:00<00:00, 11.64it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:00<00:00, 15.74it/s]\n",
            "                 all         11         16     0.0539     0.0625    0.00699    0.00164\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      2/59    0.581G    0.0799   0.03186         0    0.1118         5       640: 100% 9/9 [00:00<00:00, 12.44it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:00<00:00, 15.26it/s]\n",
            "                 all         11         16     0.0586      0.125     0.0147      0.002\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      3/59    0.581G   0.06916   0.02864         0    0.0978         6       640: 100% 9/9 [00:00<00:00, 13.25it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:00<00:00, 14.91it/s]\n",
            "                 all         11         16     0.0291      0.312     0.0166    0.00246\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      4/59    0.581G   0.08308   0.03253         0    0.1156        11       640: 100% 9/9 [00:00<00:00, 11.95it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:00<00:00, 15.19it/s]\n",
            "                 all         11         16     0.0337       0.25     0.0174    0.00375\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      5/59    0.581G   0.08992   0.03441         0    0.1243        10       640: 100% 9/9 [00:00<00:00, 12.72it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:00<00:00, 15.70it/s]\n",
            "                 all         11         16     0.0409       0.25      0.021    0.00454\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      6/59    0.581G   0.07353   0.03029         0    0.1038         6       640: 100% 9/9 [00:00<00:00, 12.83it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:00<00:00, 16.11it/s]\n",
            "                 all         11         16     0.0499      0.312     0.0277     0.0048\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      7/59    0.581G   0.08036   0.03058         0    0.1109         9       640: 100% 9/9 [00:00<00:00, 13.59it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:00<00:00, 14.27it/s]\n",
            "                 all         11         16     0.0479      0.286     0.0272     0.0062\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      8/59    0.581G   0.08495   0.03096         0    0.1159         4       640: 100% 9/9 [00:00<00:00, 12.42it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:00<00:00, 15.78it/s]\n",
            "                 all         11         16     0.0773       0.25     0.0476    0.00783\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      9/59    0.581G   0.06779   0.02878         0   0.09657         6       640: 100% 9/9 [00:00<00:00, 13.85it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:00<00:00, 14.73it/s]\n",
            "                 all         11         16     0.0781      0.438     0.0504    0.00842\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     10/59    0.581G   0.08321   0.03217         0    0.1154         7       640: 100% 9/9 [00:00<00:00, 12.85it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:00<00:00, 16.18it/s]\n",
            "                 all         11         16     0.0932       0.25     0.0498     0.0102\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     11/59    0.581G   0.07101    0.0336         0    0.1046         8       640: 100% 9/9 [00:00<00:00, 13.46it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:00<00:00, 14.66it/s]\n",
            "                 all         11         16      0.136      0.312     0.0716     0.0148\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     12/59    0.581G   0.06519   0.03262         0   0.09782         6       640: 100% 9/9 [00:00<00:00, 13.78it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:00<00:00, 16.11it/s]\n",
            "                 all         11         16      0.112        0.3      0.075     0.0211\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     13/59    0.581G   0.08284   0.03656         0    0.1194         7       640: 100% 9/9 [00:00<00:00, 12.53it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:00<00:00, 16.58it/s]\n",
            "                 all         11         16      0.195       0.25      0.127     0.0341\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     14/59    0.581G   0.07294   0.03577         0    0.1087        12       640: 100% 9/9 [00:00<00:00, 13.85it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:00<00:00, 15.04it/s]\n",
            "                 all         11         16      0.141      0.438      0.147      0.041\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     15/59    0.581G   0.07102   0.03761         0    0.1086         6       640: 100% 9/9 [00:00<00:00, 14.04it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:00<00:00, 17.13it/s]\n",
            "                 all         11         16      0.209      0.375      0.146     0.0393\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     16/59    0.581G   0.06913   0.03517         0    0.1043         5       640: 100% 9/9 [00:00<00:00, 13.69it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:00<00:00, 16.14it/s]\n",
            "                 all         11         16      0.188       0.58       0.18     0.0448\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     17/59    0.581G   0.07992   0.03992         0    0.1198        10       640: 100% 9/9 [00:00<00:00, 14.01it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:00<00:00, 17.74it/s]\n",
            "                 all         11         16      0.268      0.438      0.211     0.0552\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     18/59    0.581G   0.06368   0.03501         0    0.0987        10       640: 100% 9/9 [00:00<00:00, 13.71it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:00<00:00, 17.27it/s]\n",
            "                 all         11         16      0.226      0.625      0.209      0.061\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     19/59    0.581G   0.06193   0.02785         0   0.08978         5       640: 100% 9/9 [00:00<00:00, 12.52it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:00<00:00, 16.54it/s]\n",
            "                 all         11         16      0.206      0.688       0.22     0.0737\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     20/59    0.581G   0.06154   0.04077         0    0.1023         7       640: 100% 9/9 [00:00<00:00, 14.26it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:00<00:00, 17.81it/s]\n",
            "                 all         11         16      0.331      0.375      0.265     0.0937\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     21/59    0.581G   0.06855   0.03565         0    0.1042         8       640: 100% 9/9 [00:00<00:00, 14.20it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:00<00:00, 18.47it/s]\n",
            "                 all         11         16      0.499      0.438      0.391      0.145\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     22/59    0.581G   0.06322   0.03346         0   0.09668         8       640: 100% 9/9 [00:00<00:00, 13.95it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:00<00:00, 15.69it/s]\n",
            "                 all         11         16      0.415       0.62      0.388      0.133\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     23/59    0.581G   0.06454   0.03663         0    0.1012        10       640: 100% 9/9 [00:00<00:00, 14.32it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:00<00:00, 17.18it/s]\n",
            "                 all         11         16      0.447      0.625      0.423      0.141\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     24/59    0.581G   0.06828   0.03574         0     0.104        10       640: 100% 9/9 [00:00<00:00, 14.04it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:00<00:00, 18.76it/s]\n",
            "                 all         11         16      0.496      0.616      0.467      0.166\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     25/59    0.581G   0.06049   0.04508         0    0.1056         7       640: 100% 9/9 [00:00<00:00, 14.25it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:00<00:00, 16.56it/s]\n",
            "                 all         11         16      0.555      0.625      0.532       0.17\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     26/59    0.581G   0.05657   0.03804         0   0.09461        15       640: 100% 9/9 [00:00<00:00, 13.01it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:00<00:00, 18.81it/s]\n",
            "                 all         11         16      0.726      0.496      0.556      0.213\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     27/59    0.581G   0.05361   0.03857         0   0.09219         5       640: 100% 9/9 [00:00<00:00, 14.34it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:00<00:00, 16.52it/s]\n",
            "                 all         11         16      0.688      0.562       0.57      0.244\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     28/59    0.583G   0.06834   0.04361         0    0.1119        11       640: 100% 9/9 [00:00<00:00, 14.16it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:00<00:00, 18.99it/s]\n",
            "                 all         11         16      0.665       0.62      0.598      0.254\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     29/59    0.583G   0.05371   0.03659         0    0.0903        12       640: 100% 9/9 [00:00<00:00, 13.60it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:00<00:00, 18.14it/s]\n",
            "                 all         11         16      0.679      0.562      0.605      0.273\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     30/59    0.583G   0.06935   0.04353         0    0.1129         5       640: 100% 9/9 [00:00<00:00, 13.72it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:00<00:00, 18.86it/s]\n",
            "                 all         11         16      0.664      0.562      0.603      0.278\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     31/59    0.583G   0.07055   0.03735         0    0.1079         9       640: 100% 9/9 [00:00<00:00, 13.65it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:00<00:00, 19.39it/s]\n",
            "                 all         11         16      0.775        0.5      0.606      0.276\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     32/59    0.583G   0.05732   0.03987         0   0.09719        14       640: 100% 9/9 [00:00<00:00, 14.06it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:00<00:00, 18.49it/s]\n",
            "                 all         11         16       0.62      0.612      0.585      0.254\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     33/59    0.583G   0.05804   0.03365         0    0.0917         6       640: 100% 9/9 [00:00<00:00, 13.42it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:00<00:00, 18.66it/s]\n",
            "                 all         11         16      0.792        0.5      0.578      0.278\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     34/59    0.583G   0.06214   0.03539         0   0.09753         6       640: 100% 9/9 [00:00<00:00, 14.49it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:00<00:00, 18.84it/s]\n",
            "                 all         11         16      0.889      0.562      0.668      0.286\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     35/59    0.583G   0.05532   0.03156         0   0.08689         8       640: 100% 9/9 [00:00<00:00, 13.81it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:00<00:00, 19.71it/s]\n",
            "                 all         11         16      0.889        0.5      0.646      0.295\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     36/59    0.583G   0.05375   0.04366         0   0.09742         6       640: 100% 9/9 [00:00<00:00, 14.41it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:00<00:00, 17.57it/s]\n",
            "                 all         11         16      0.889        0.5      0.646      0.295\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     37/59    0.583G   0.04761   0.02577         0   0.07337         5       640: 100% 9/9 [00:00<00:00, 14.54it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:00<00:00, 19.33it/s]\n",
            "                 all         11         16      0.688      0.553      0.644      0.272\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     38/59    0.583G   0.05372   0.03223         0   0.08595         5       640: 100% 9/9 [00:00<00:00, 14.66it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:00<00:00, 19.79it/s]\n",
            "                 all         11         16      0.881        0.5      0.672      0.276\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     39/59    0.583G   0.05461   0.03975         0   0.09435         8       640: 100% 9/9 [00:00<00:00, 13.38it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:00<00:00, 20.18it/s]\n",
            "                 all         11         16      0.889      0.499      0.655       0.32\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     40/59    0.583G    0.0501   0.03457         0   0.08468         4       640: 100% 9/9 [00:00<00:00, 14.99it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:00<00:00, 19.28it/s]\n",
            "                 all         11         16      0.889      0.499      0.655       0.32\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     41/59    0.583G    0.0458   0.03651         0   0.08231        13       640: 100% 9/9 [00:00<00:00, 13.47it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:00<00:00, 19.79it/s]\n",
            "                 all         11         16      0.889        0.5      0.666       0.32\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     42/59    0.583G   0.04773   0.03308         0   0.08082        11       640: 100% 9/9 [00:00<00:00, 13.93it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:00<00:00, 19.35it/s]\n",
            "                 all         11         16      0.885        0.5      0.654      0.324\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     43/59    0.583G   0.06007   0.03777         0   0.09784         7       640: 100% 9/9 [00:00<00:00, 13.84it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:00<00:00, 19.38it/s]\n",
            "                 all         11         16      0.885        0.5      0.654      0.324\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     44/59    0.583G   0.04951   0.03711         0   0.08662         9       640: 100% 9/9 [00:00<00:00, 13.86it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:00<00:00, 20.19it/s]\n",
            "                 all         11         16      0.691      0.562      0.645      0.323\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     45/59    0.583G   0.05045   0.03332         0   0.08377         9       640: 100% 9/9 [00:00<00:00, 14.56it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:00<00:00, 20.18it/s]\n",
            "                 all         11         16      0.816      0.562       0.68      0.345\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     46/59    0.583G    0.0435   0.03034         0   0.07384         4       640: 100% 9/9 [00:00<00:00, 14.82it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:00<00:00, 19.82it/s]\n",
            "                 all         11         16      0.816      0.562       0.68      0.345\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     47/59    0.583G   0.05106   0.03391         0   0.08496        11       640: 100% 9/9 [00:00<00:00, 12.87it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:00<00:00, 19.41it/s]\n",
            "                 all         11         16        0.9      0.561      0.705      0.335\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     48/59    0.583G   0.05115   0.03538         0   0.08653         4       640: 100% 9/9 [00:00<00:00, 13.66it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:00<00:00, 20.43it/s]\n",
            "                 all         11         16      0.898      0.562      0.716      0.375\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     49/59    0.583G   0.04595    0.0356         0   0.08155         6       640: 100% 9/9 [00:00<00:00, 14.34it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:00<00:00, 18.67it/s]\n",
            "                 all         11         16      0.898      0.562      0.716      0.375\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     50/59    0.583G   0.04798   0.02568         0   0.07366         5       640: 100% 9/9 [00:00<00:00, 13.62it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:00<00:00, 19.72it/s]\n",
            "                 all         11         16      0.981      0.562      0.744      0.385\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     51/59    0.583G   0.03758   0.03423         0   0.07181         4       640: 100% 9/9 [00:00<00:00, 14.88it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:00<00:00, 18.06it/s]\n",
            "                 all         11         16      0.981      0.562      0.744      0.385\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     52/59    0.583G   0.04961   0.03126         0   0.08086        13       640: 100% 9/9 [00:00<00:00, 15.07it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:00<00:00, 20.33it/s]\n",
            "                 all         11         16      0.899      0.562      0.759      0.355\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     53/59    0.583G   0.04842   0.03582         0   0.08424        11       640: 100% 9/9 [00:00<00:00, 13.87it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:00<00:00, 20.19it/s]\n",
            "                 all         11         16      0.899      0.562      0.759      0.355\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     54/59    0.583G   0.05334   0.03565         0   0.08899         7       640: 100% 9/9 [00:00<00:00, 13.15it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:00<00:00, 21.20it/s]\n",
            "                 all         11         16      0.917      0.687      0.812      0.358\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     55/59    0.583G   0.03871    0.0269         0   0.06561        11       640: 100% 9/9 [00:00<00:00, 14.59it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:00<00:00, 18.75it/s]\n",
            "                 all         11         16      0.914      0.688      0.798      0.352\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     56/59    0.583G   0.03641   0.03194         0   0.06835        10       640: 100% 9/9 [00:00<00:00, 15.46it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:00<00:00, 19.86it/s]\n",
            "                 all         11         16      0.914      0.688      0.798      0.352\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     57/59    0.583G   0.05174   0.03884         0   0.09058         5       640: 100% 9/9 [00:00<00:00, 13.80it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:00<00:00, 20.39it/s]\n",
            "                 all         11         16      0.705      0.747      0.764      0.388\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     58/59    0.583G   0.04042   0.02665         0   0.06706         6       640: 100% 9/9 [00:00<00:00, 15.49it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:00<00:00, 19.35it/s]\n",
            "                 all         11         16      0.705      0.747      0.764      0.388\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     59/59    0.583G   0.04423   0.02785         0   0.07207         8       640: 100% 9/9 [00:00<00:00, 13.04it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:01<00:00,  2.28it/s]\n",
            "                 all         11         16      0.997      0.562      0.722       0.39\n",
            "60 epochs completed in 0.035 hours.\n",
            "\n",
            "Optimizer stripped from runs/train/exp4/weights/last.pt, 14.4MB\n",
            "Optimizer stripped from runs/train/exp4/weights/best.pt, 14.4MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15glLzbQx5u0"
      },
      "source": [
        "# 4. Visualize"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLI1JmHU7B0l"
      },
      "source": [
        "## Weights & Biases Logging ðŸŒŸ NEW\n",
        "\n",
        "[Weights & Biases](https://wandb.ai/site?utm_campaign=repo_yolo_notebook) (W&B) is now integrated with YOLOv5 for real-time visualization and cloud logging of training runs. This allows for better run comparison and introspection, as well improved visibility and collaboration for teams. To enable W&B `pip install wandb`, and then train normally (you will be guided through setup on first use). \n",
        "\n",
        "During training you will see live updates at [https://wandb.ai/home](https://wandb.ai/home?utm_campaign=repo_yolo_notebook), and you can create and share detailed [Reports](https://wandb.ai/glenn-jocher/yolov5_tutorial/reports/YOLOv5-COCO128-Tutorial-Results--VmlldzozMDI5OTY) of your results. For more information see the [YOLOv5 Weights & Biases Tutorial](https://github.com/ultralytics/yolov5/issues/1289). \n",
        "\n",
        "<img src=\"https://user-images.githubusercontent.com/26833433/98184457-bd3da580-1f0a-11eb-8461-95d908a71893.jpg\" width=\"800\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WPvRbS5Swl6"
      },
      "source": [
        "## Local Logging\n",
        "\n",
        "All results are logged by default to `runs/train`, with a new experiment directory created for each new training as `runs/train/exp2`, `runs/train/exp3`, etc. View train and test jpgs to see mosaics, labels, predictions and augmentation effects. Note a **Mosaic Dataloader** is used for training (shown below), a new concept developed by Ultralytics and first featured in [YOLOv4](https://arxiv.org/abs/2004.10934)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "riPdhraOTCO0"
      },
      "source": [
        "Image(filename='runs/train/exp/train_batch0.jpg', width=800)  # train batch 0 mosaics and labels\n",
        "Image(filename='runs/train/exp/test_batch0_labels.jpg', width=800)  # test batch 0 labels\n",
        "Image(filename='runs/train/exp/test_batch0_pred.jpg', width=800)  # test batch 0 predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYG4WFEnTVrI"
      },
      "source": [
        "> <img src=\"https://user-images.githubusercontent.com/26833433/83667642-90fcb200-a583-11ea-8fa3-338bbf7da194.jpeg\" width=\"750\">  \n",
        "`train_batch0.jpg` shows train batch 0 mosaics and labels\n",
        "\n",
        "> <img src=\"https://user-images.githubusercontent.com/26833433/83667626-8c37fe00-a583-11ea-997b-0923fe59b29b.jpeg\" width=\"750\">  \n",
        "`test_batch0_labels.jpg` shows test batch 0 labels\n",
        "\n",
        "> <img src=\"https://user-images.githubusercontent.com/26833433/83667635-90641b80-a583-11ea-8075-606316cebb9c.jpeg\" width=\"750\">  \n",
        "`test_batch0_pred.jpg` shows test batch 0 _predictions_\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KN5ghjE6ZWh"
      },
      "source": [
        "Training losses and performance metrics are also logged to [Tensorboard](https://www.tensorflow.org/tensorboard) and a custom `results.txt` logfile which is plotted as `results.png` (below) after training completes. Here we show YOLOv5s trained on COCO128 to 300 epochs, starting from scratch (blue), and from pretrained `--weights yolov5s.pt` (orange)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDznIqPF7nk3"
      },
      "source": [
        "from utils.plots import plot_results \n",
        "plot_results(save_dir='runs/train/exp')  # plot all results*.txt as results.png\n",
        "Image(filename='runs/train/exp/results.png', width=800)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfrEegCSW3fK"
      },
      "source": [
        "<img src=\"https://user-images.githubusercontent.com/26833433/97808309-8182b180-1c66-11eb-8461-bffe1a79511d.png\" width=\"800\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zelyeqbyt3GD"
      },
      "source": [
        "# Environments\n",
        "\n",
        "YOLOv5 may be run in any of the following up-to-date verified environments (with all dependencies including [CUDA](https://developer.nvidia.com/cuda)/[CUDNN](https://developer.nvidia.com/cudnn), [Python](https://www.python.org/) and [PyTorch](https://pytorch.org/) preinstalled):\n",
        "\n",
        "- **Google Colab and Kaggle** notebooks with free GPU: <a href=\"https://colab.research.google.com/github/ultralytics/yolov5/blob/master/tutorial.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"></a> <a href=\"https://www.kaggle.com/ultralytics/yolov5\"><img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" alt=\"Open In Kaggle\"></a>\n",
        "- **Google Cloud** Deep Learning VM. See [GCP Quickstart Guide](https://github.com/ultralytics/yolov5/wiki/GCP-Quickstart)\n",
        "- **Amazon** Deep Learning AMI. See [AWS Quickstart Guide](https://github.com/ultralytics/yolov5/wiki/AWS-Quickstart)\n",
        "- **Docker Image**. See [Docker Quickstart Guide](https://github.com/ultralytics/yolov5/wiki/Docker-Quickstart) <a href=\"https://hub.docker.com/r/ultralytics/yolov5\"><img src=\"https://img.shields.io/docker/pulls/ultralytics/yolov5?logo=docker\" alt=\"Docker Pulls\"></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Qu7Iesl0p54"
      },
      "source": [
        "# Status\n",
        "\n",
        "![CI CPU testing](https://github.com/ultralytics/yolov5/workflows/CI%20CPU%20testing/badge.svg)\n",
        "\n",
        "If this badge is green, all [YOLOv5 GitHub Actions](https://github.com/ultralytics/yolov5/actions) Continuous Integration (CI) tests are currently passing. CI tests verify correct operation of YOLOv5 training ([train.py](https://github.com/ultralytics/yolov5/blob/master/train.py)), testing ([test.py](https://github.com/ultralytics/yolov5/blob/master/test.py)), inference ([detect.py](https://github.com/ultralytics/yolov5/blob/master/detect.py)) and export ([export.py](https://github.com/ultralytics/yolov5/blob/master/export.py)) on MacOS, Windows, and Ubuntu every 24 hours and on every commit.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEijrePND_2I"
      },
      "source": [
        "# Appendix\n",
        "\n",
        "Optional extras below. Unit tests validate repo functionality and should be run on any PRs submitted.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gI6NoBev8Ib1"
      },
      "source": [
        "# Re-clone repo\n",
        "%cd ..\n",
        "%rm -rf yolov5 && git clone https://github.com/ultralytics/yolov5\n",
        "%cd yolov5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcKoSIK2WSzj"
      },
      "source": [
        "# Reproduce\n",
        "for x in 'yolov5s', 'yolov5m', 'yolov5l', 'yolov5x':\n",
        "  !python test.py --weights {x}.pt --data coco.yaml --img 640 --conf 0.25 --iou 0.45  # speed\n",
        "  !python test.py --weights {x}.pt --data coco.yaml --img 640 --conf 0.001 --iou 0.65  # mAP"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMusP4OAxFu6"
      },
      "source": [
        "# PyTorch Hub\n",
        "import torch\n",
        "\n",
        "# Model\n",
        "model = torch.hub.load('ultralytics/yolov5', 'yolov5s')\n",
        "\n",
        "# Images\n",
        "dir = 'https://github.com/ultralytics/yolov5/raw/master/data/images/'\n",
        "imgs = [dir + f for f in ('zidane.jpg', 'bus.jpg')]  # batch of images\n",
        "\n",
        "# Inference\n",
        "results = model(imgs)\n",
        "results.print()  # or .show(), .save()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGH0ZjkGjejy"
      },
      "source": [
        "# Unit tests\n",
        "%%shell\n",
        "export PYTHONPATH=\"$PWD\"  # to run *.py. files in subdirectories\n",
        "\n",
        "rm -rf runs  # remove runs/\n",
        "for m in yolov5s; do  # models\n",
        "  python train.py --weights $m.pt --epochs 3 --img 320 --device 0  # train pretrained\n",
        "  python train.py --weights '' --cfg $m.yaml --epochs 3 --img 320 --device 0  # train scratch\n",
        "  for d in 0 cpu; do  # devices\n",
        "    python detect.py --weights $m.pt --device $d  # detect official\n",
        "    python detect.py --weights runs/train/exp/weights/best.pt --device $d  # detect custom\n",
        "    python test.py --weights $m.pt --device $d # test official\n",
        "    python test.py --weights runs/train/exp/weights/best.pt --device $d # test custom\n",
        "  done\n",
        "  python hubconf.py  # hub\n",
        "  python models/yolo.py --cfg $m.yaml  # inspect\n",
        "  python export.py --weights $m.pt --img 640 --batch 1  # export\n",
        "done"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gogI-kwi3Tye"
      },
      "source": [
        "# Profile\n",
        "from utils.torch_utils import profile \n",
        "\n",
        "m1 = lambda x: x * torch.sigmoid(x)\n",
        "m2 = torch.nn.SiLU()\n",
        "profile(x=torch.randn(16, 3, 640, 640), ops=[m1, m2], n=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVRSOhEvUdb5"
      },
      "source": [
        "# Evolve\n",
        "!python train.py --img 640 --batch 64 --epochs 100 --data coco128.yaml --weights yolov5s.pt --cache --noautoanchor --evolve\n",
        "!d=runs/train/evolve && cp evolve.* $d && zip -r evolve.zip $d && gsutil mv evolve.zip gs://bucket  # upload results (optional)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSgFCAcMbk1R"
      },
      "source": [
        "# VOC\n",
        "for b, m in zip([64, 48, 32, 16], ['yolov5s', 'yolov5m', 'yolov5l', 'yolov5x']):  # zip(batch_size, model)\n",
        "  !python train.py --batch {b} --weights {m}.pt --data VOC.yaml --epochs 50 --cache --img 512 --nosave --hyp hyp.finetune.yaml --project VOC --name {m}"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}